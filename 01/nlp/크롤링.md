### Beutiful Soup의 한계
- 웹페이지의 자바스크립트로 생성된 파트는 크롤링이 불가능.
- 스크롤을 내려야 나오는 부분이나, 화면이 움직이는 부분, 계속해서 내용이 바뀌는 댓글 창 등

따라서 자바스크립트로 생성된 페이지의 크롤링에는 파이썬 셀레니움이 필요합니다.

그러나 정적 html에 포함된 내용이라면
Beautiful Soup만으로도 정적 HTML에 포함된 링크를 따라 새 페이지로 이동하여 정보를 추출하고 다시 이전 페이지로 돌아갈 수 있습니다13.

이 과정은 다음과 같이 진행됩니다:

현재 페이지에서 Beautiful Soup를 사용하여 링크를 추출합니다.

추출한 링크로 새로운 HTTP 요청을 보냅니다.

새 페이지의 HTML을 Beautiful Soup로 파싱하여 원하는 정보를 추출합니다.

추출한 정보를 저장합니다.

다음 링크로 이동하거나 원래 페이지로 돌아갑니다.

1. 셀레니움 (Selenium):
장점:
실제 브라우저를 실행하므로 UI 요소 조작 및 테스트가 가능합니다.
다양한 브라우저 및 언어 지원으로 유연한 환경을 제공합니다.
크로스 브라우징 테스트, 웹 스크래핑, 웹 페이지 성능 측정 등 다양한 분야에 활용 가능합니다.
웹 애플리케이션 테스트 자동화에 적합합니다.
단점:
실제 브라우저를 실행하기 때문에 속도가 느린 편입니다.
JavaScript 실행 시간이 추가로 소요될 수 있습니다.
웹 컨트롤(클릭)이 필요할 때 requests 방법보다 Selenium을 사용하는 것이 일반적이지만, 요청만 필요한 경우 requests가 더 유리합니다. 
2. Scrapy:
장점:
서버에서 HTML을 직접 받아오고 분석하는 과정이 매우 효율적이며, 비동기적으로 여러 페이지를 동시에 크롤링할 수 있습니다. 
속도가 빠릅니다. 
단점:
JavaScript 렌더링이 필요한 웹 페이지 크롤링에는 적합하지 않습니다. 
웹 컨트롤(클릭)이 필요한 작업에는 Selenium이 더 적합합니다. 
3. Playwright:
장점:
Selenium보다 더 직관적인 인터페이스와 사용 편의성을 제공합니다.
빠른 속도로 테스트를 수행할 수 있습니다.
단점:
Selenium만큼의 높은 인지도를 가지고 있지는 않습니다.
Selenium과 같은 오래된 UI 요소 식별 방법 대신 HTML 태그, 텍스트 기반의 식별 방법을 권장합니다

```python title:dbpia.py
import scrapy
from scrapy_playwright.page import PageMethod

class DbpiaSpider(scrapy.Spider):
    name = "dbpia"

    def start_requests(self):
        query = input('검색어를 입력해주세요: ')
        yield scrapy.Request(
            url=f"https://www.dbpia.co.kr/search/topSearch?searchOption=all&query={query}",
            meta={
                "playwright": True,  # Enable Playwright for JavaScript rendering
                "playwright_include_page": True,  # Include Playwright page object
                "playwright_page_methods": [
                    PageMethod("wait_for_selector", '#searchResultList > article:nth-child(1)'),
                    PageMethod('wait_for_selector', '#selectWrapper'),
                    PageMethod('click', '#selectWrapper'),
                    PageMethod('wait_for_selector', '#get100PerPage'),
                    PageMethod('click', '#get100PerPage')
                ],
            },
            callback=self.parse
        )

    def parse(self, response):
        title = response.css("#searchResultList > article:nth-child(1) .thesis__tit::text").get()
        year_month = response.css("#searchResultList > article:nth-child(1) .thesis__item:nth-child(4)::text").get()
        if title:
            self.log(f"제목: {title}")
        else:
            self.log("제목을 찾지 못했습니다.")

```
